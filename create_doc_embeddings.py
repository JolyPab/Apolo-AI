import os
import json
from dotenv import load_dotenv
from docx import Document
from langchain_openai import AzureOpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from tqdm import tqdm

"""–°–∫—Ä–∏–ø—Ç —Å–æ–∑–¥–∞—ë—Ç FAISS-–∏–Ω–¥–µ–∫—Å –∏–∑ —Ç–µ–∫—Å—Ç–∞ .docx-—Ñ–∞–π–ª–∞
Usage:
    python create_doc_embeddings.py <path_to_docx> [index_dir]
–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é index_dir = "doc_faiss".
"""

import sys

# --- cli args ---------------------------------------------------------------
if len(sys.argv) < 2:
    print("Uso: python create_doc_embeddings.py <archivo.docx> [directorio_indice]")
    sys.exit(1)

docx_path = sys.argv[1]
index_dir = sys.argv[2] if len(sys.argv) > 2 else "doc_faiss"

# --- env & embeddings -------------------------------------------------------
load_dotenv()
embeddings_model = AzureOpenAIEmbeddings(
    api_key=os.getenv("AZURE_EMBEDDINGS_API_KEY"),
    azure_endpoint=os.getenv("AZURE_EMBEDDINGS_ENDPOINT"),
    deployment="text-embedding-ada-002",
    api_version="2023-05-15",
)

# --- extract text -----------------------------------------------------------
print(f"üìñ Extrayendo texto de {docx_path}‚Ä¶")
doc = Document(docx_path)
paragraphs = [p.text.strip() for p in doc.paragraphs if p.text.strip()]

# --- extract text from tables ---------------------------------------------
for tbl in doc.tables:
    for row in tbl.rows:
        cells = [c.text.strip() for c in row.cells if c.text.strip()]
        if cells:
            paragraphs.append(" | ".join(cells))

print(f"üí° {len(paragraphs)} p√°rrafos encontrados. Generando embeddings‚Ä¶")

# --- chunking ---------------------------------------------------------------
CHUNK_SIZE = 4  # –∞–±–∑–∞—Ü–µ–≤ –≤ –æ–¥–Ω–æ–º —á–∞–Ω–∫–µ
faiss_index = None
chunk = []

for para in tqdm(paragraphs, desc="Embeddings"):
    chunk.append(para)
    if len(chunk) >= CHUNK_SIZE:
        text = "\n".join(chunk)
        emb = FAISS.from_texts([text], embeddings_model)
        if faiss_index is None:
            faiss_index = emb
        else:
            faiss_index.merge_from(emb)
        chunk = []

# –æ—Å—Ç–∞—Ç–æ–∫
if chunk:
    text = "\n".join(chunk)
    emb = FAISS.from_texts([text], embeddings_model)
    if faiss_index is None:
        faiss_index = emb
    else:
        faiss_index.merge_from(emb)

# --- save -------------------------------------------------------------------
faiss_index.save_local(index_dir)
print(f"‚úÖ √çndice guardado en {index_dir}") 